{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1087373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in property_dict.items():\n",
    "    dt_tag = room_item.find('dt', text=j)\n",
    "    if dt_tag:\n",
    "        dd_tag = dt_tag.find_next('dd')\n",
    "        if dd_tag:\n",
    "            temp_property_data[i] = dd_tag.text.strip()\n",
    "        else:\n",
    "            temp_property_data[i] = ''\n",
    "    else:\n",
    "        temp_property_data[i] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721f28f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mカーネルを起動できませんでした。 \n",
      "\u001b[1;31mJupyter サーバーがクラッシュしました。接続できません。\n",
      "\u001b[1;31mJupyter のエラー コード: 1\n",
      "\u001b[1;31mError executing Jupyter command 'notebook': [Errno 2] No such file or directory. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "temp_property_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7954063",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mカーネルを起動できませんでした。 \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31mError executing Jupyter command 'notebook': [Errno 2] No such file or directory. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# cofing: utf-8\n",
    "\n",
    "# from retry import retry\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import math\n",
    "# from logging import getLogger, StreamHandler, Formatter, FileHandler, DEBUG\n",
    "import yaml\n",
    "import os\n",
    "from retry import retry\n",
    "import sys\n",
    "import time\n",
    "\n",
    "notebook = True\n",
    "if notebook:\n",
    "    work_dir = '/Users/satomitakei/property_valuation_calculator'\n",
    "    with open(work_dir + '/setting/kenbiya_scraping_config.yaml', 'r') as yml:\n",
    "        config = yaml.safe_load(yml)\n",
    "    area_name = 'tokyo'\n",
    "else:\n",
    "    work_dir = os.getcwd()\n",
    "    with open(work_dir + '/setting/kenbiya_scraping_config.yaml', 'r') as yml:\n",
    "        config = yaml.safe_load(yml)\n",
    "    area_name = sys.argv[1]\n",
    "if area_name == 'tokyo':\n",
    "    base_url = config['base_url_tokyo']\n",
    "elif area_name == 'osaka':\n",
    "    base_url = config['base_url_osaka']\n",
    "elif area_name == 'fukuoka':\n",
    "    base_url = config['base_url_fukuoka']\n",
    "\n",
    "def write_log(log_file, text):\n",
    "    f = open(log_file, 'a', encoding='UTF-8')\n",
    "    # f.write(text)\n",
    "    # f.close()\n",
    "    print(text)\n",
    "\n",
    "diff_jst_from_utc = 0\n",
    "start_time = dt.datetime.now() + dt.timedelta(hours=diff_jst_from_utc)\n",
    "now_time = (dt.datetime.now() +\n",
    "            dt.timedelta(hours=diff_jst_from_utc)).strftime('%Y%m%d_%H%M')\n",
    "\n",
    "log_dir = work_dir + f'/log/scraping'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_file = log_dir + f'/{now_time}_log.txt'\n",
    "f = open(log_file, 'w', encoding='UTF-8')\n",
    "f.close()\n",
    "\n",
    "text = 'processing_start_time:' + str(start_time.replace(microsecond=0)) + '\\n'\n",
    "write_log(log_file, text)\n",
    "excution_date = dt.datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "# file_name = 'suumo_baibai'\n",
    "# excution_date = dt.datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    return soup\n",
    "# @retry(tries=3, delay=10, backoff=2)\n",
    "# def main():\n",
    "all_data = []\n",
    "\n",
    "# 基本ページurl \n",
    "page = '1'\n",
    "url = base_url.format(page = page)\n",
    "write_log(log_file,'base_url:'+url)\n",
    "# get html\n",
    "item = get_html(url)\n",
    "\n",
    "# extract all items\n",
    "total_rooms = int(re.sub(r\"\\D\", \"\",item.find(True,\"strong\", class_=\"result_num\").get_text()))\n",
    "max_page = math.floor(total_rooms/50)+ 1\n",
    "text = f\"max_page:{max_page} \\n\"\n",
    "write_log(log_file,text)\n",
    "\n",
    "url_list = []\n",
    "all_data = []\n",
    "error_page = []\n",
    "# 物件URLの取得\n",
    "data= {}\n",
    "\n",
    "def extract_value(pattern,temp_property):\n",
    "    match = re.search(pattern, temp_property)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "# for i in tqdm(range(max_page+1)): \n",
    "for i in tqdm(range(2)): \n",
    "    url = base_url.format(page = str(i))\n",
    "    # get html\n",
    "    item = get_html(url)\n",
    "    for j in item.findAll(href=re.compile(\"pp1/s/.*/re_.*/\")):\n",
    "        room_url = 'https://www.kenbiya.com/'+j.get('href')\n",
    "        room_item = get_html(room_url)\n",
    "        property_dict = {\n",
    "            'price': '価格',\n",
    "            'transportation': '交通',\n",
    "            'address': '住所',\n",
    "            'year_built': '築年月',\n",
    "            'building_structure': '建物構造/階数',\n",
    "            'exclusive_area': '専有面積',\n",
    "            'floor_plan': '間取り',\n",
    "            'transaction_method': '取引態様',\n",
    "            'delivery': '引渡',\n",
    "            'current_condition': '現況',\n",
    "            'cap_rate': '満室時利回り',\n",
    "            'full_occupancy_incom': '満室時年収/月収',\n",
    "            'property_name': '物件名',\n",
    "            'land_rights': '土地権利',\n",
    "            'management_fee_repair_reserve_fund': '管理費/修繕積立',\n",
    "            'management_company': '管理会社',\n",
    "            'management_method': '管理方式/管理人',\n",
    "            'last_update_date': '直前の更新日',\n",
    "            'scheduled_update_date': '更新予定日',\n",
    "            'management_id': '管理ID'\n",
    "        }\n",
    "        temp_property_data={}\n",
    "        for i, j in property_dict.items():\n",
    "            dt_tag = room_item.find('dt', text=j)\n",
    "            if dt_tag:\n",
    "                dd_tag = dt_tag.find_next('dd')\n",
    "                if dd_tag:\n",
    "                    temp_property_data[i] = dd_tag.text.strip()\n",
    "                else:\n",
    "                    temp_property_data[i] = ''\n",
    "            else:\n",
    "                temp_property_data[i] = ''\n",
    "        try:\n",
    "            # 物件詳細のデータを収集\n",
    "            # マンション名\n",
    "            data[\"property_name\"] = temp_property_data['property_name']\n",
    "\n",
    "            # 価格\n",
    "            data[\"price\"] = int(temp_property_data['price'].replace(',', '').replace('万円', '')) * 10000\n",
    "\n",
    "            # 交通\n",
    "            data[\"train_line\"] = temp_property_data['transportation'].split()[0]\n",
    "            data[\"station\"] = temp_property_data['transportation'].split()[1]\n",
    "            temp_minutes_from_station = temp_property_data['transportation'].split()[2]\n",
    "            pattern = r'徒歩(\\d.+)分'\n",
    "            data[\"minutes_from_station\"] = extract_value(pattern,temp_minutes_from_station)\n",
    "\n",
    "            # 住所\n",
    "            temp_address= temp_property_data['address']\n",
    "            pattern = r'^(.+(都|道|府|県))'\n",
    "            data[\"prefecture_name\"] = extract_value(pattern,temp_address)\n",
    "            pattern = r'^(.+(市|区))'\n",
    "            data[\"city_name\"] = extract_value(pattern,temp_address)\n",
    "            data[\"town_name\"] = temp_address.replace(data[\"prefecture_name\"],'').replace(data[\"city_name\"],'')\n",
    "\n",
    "            # 築年数\n",
    "            temp_year_built = temp_property_data['year_built']\n",
    "            pattern = r'（築(\\d.+)年）'\n",
    "            data[\"year_built\"] = int(extract_value(pattern,temp_year_built))\n",
    "\n",
    "            # 構造\n",
    "            temp_building_structure= temp_property_data['building_structure']\n",
    "            pattern = r'^(.+)造'\n",
    "            data[\"structure\"] = extract_value(pattern,temp_building_structure)\n",
    "\n",
    "            pattern = r'^.+造(\\d+)階'\n",
    "            data[\"floor\"] = extract_value(pattern,temp_building_structure)\n",
    "\n",
    "            pattern = r'^.+(\\d.+)階建'\n",
    "            data[\"max_floor\"] = extract_value(pattern,temp_building_structure)\n",
    "\n",
    "            # 総戸数\n",
    "            temp_total_rooms = temp_property_data['building_structure'].strip()\n",
    "            pattern = r'総戸数(\\d+)戸'\n",
    "            data[\"total_rooms\"] = extract_value(pattern,temp_total_rooms)\n",
    "\n",
    "            # 専有面積\n",
    "            temp_exclusive_area= temp_property_data['exclusive_area']\n",
    "            pattern = r'^(\\d.+)m²'\n",
    "            data[\"exclusive_area\"] = extract_value(pattern,temp_exclusive_area)\n",
    "\n",
    "            # 間取り\n",
    "            data[\"floor_plan\"] = temp_property_data['floor_plan'].split()[0]\n",
    "\n",
    "            # 方角\n",
    "            data[\"direction\"] = temp_property_data['floor_plan'].split()[1]\n",
    "\n",
    "            # 取引態様\n",
    "            data[\"transaction_method\"] = temp_property_data['transaction_method']\n",
    "\n",
    "            # 引渡\n",
    "            data[\"delivery\"] = temp_property_data['delivery']\n",
    "\n",
    "            # 現況\n",
    "            data[\"current_condition\"] = temp_property_data['current_condition']\n",
    "\n",
    "            # 満室時利回り\n",
    "            data[\"cap_rate\"] = float(temp_property_data['cap_rate'].replace('％','')) / 100\n",
    "\n",
    "            # 満室時年収\n",
    "            data[\"full_occupancy_incom\"] = int(float(temp_property_data['full_occupancy_incom'].split()[0].replace('万円','')) * 10000)\n",
    "\n",
    "            # 土地権利\n",
    "            data[\"land_rights\"] = temp_property_data['land_rights']\n",
    "\n",
    "            # 'management_fee_repair_reserve_fund': '管理費/修繕積立',\n",
    "            data[\"management_fee\"] = int(temp_property_data['management_fee_repair_reserve_fund'].split('/')[0].replace('円','').replace(',',''))\n",
    "            data[\"repair_reserve_fund\"] = int(temp_property_data['management_fee_repair_reserve_fund'].split('/')[1].replace('円','').replace(',',''))\n",
    "\n",
    "            # 管理会社\n",
    "            data[\"management_company\"] = temp_property_data['management_company']\n",
    "\n",
    "            # 'management_method': '管理方式/管理人',\n",
    "            data[\"management_method\"] = re.findall('(.*)\\r\\n  \\r\\n*', temp_property_data['management_method'].split('/')[0])[0]\n",
    "            data[\"management_person\"] = re.findall('\\r\\n    (.*)', temp_property_data['management_method'].split('/')[1])[0]\n",
    "\n",
    "            # 直前の更新日\n",
    "            date_format = '%Y年%m月%d日'\n",
    "            text = temp_property_data['last_update_date'].replace(' ','')\n",
    "            data[\"last_update_date\"] = datetime.strptime(text, date_format).date()\n",
    "\n",
    "\n",
    "            # 'scheduled_update_date': '更新予定日',\n",
    "            text = temp_property_data['scheduled_update_date'].replace(' ','')\n",
    "            data[\"scheduled_update_date\"] = datetime.strptime(text, date_format).date()\n",
    "\n",
    "            # 'management_id': '管理ID'\n",
    "            data[\"management_id\"] = temp_property_data['management_id']\n",
    "            write_log(log_file,'Done:'+data[\"property_name\"])\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "            write_log(log_file,'error')\n",
    "        \n",
    "        #     \n",
    "        #     data[\"exclusive_area\"] = room_item.findAll(\"td\", {\"class\": \"w290 bdCell\"})[4].getText().strip()\n",
    "        #     data[\"other_area\"] = room_item.findAll(\"td\", {\"class\": \"w290 bdCell\"})[5].getText().strip()\n",
    "        #     data[\"stories\"] = room_item.findAll(\"td\", {\"class\": \"w290 bdCell\"})[6].getText().strip()\n",
    "        #     data[\"completion\"] = room_item.findAll(\"td\", {\"class\": \"w290 bdCell\"})[7].getText().strip()\n",
    "        #     data[\"adress\"] = room_item.findAll(\"td\", {\"class\": \"w290 bdCell\"})[8].getText().strip()\n",
    "        #     data[\"access\"] = room_item.findAll(\"td\", {\"class\": \"w290 bdCell\"})[9].getText().strip()\n",
    "\n",
    "        #     # 物件詳細概要ページからのデータを取得\n",
    "        #     room_detail_item = get_html(room_detail_url)\n",
    "        #     data[\"move_in_date\"] = room_detail_item.findAll(\"td\", {\"class\": \"w299 bdCell\"})[12].getText().strip()\n",
    "        #     data[\"direction\"] = room_detail_item.findAll(\"td\", {\"class\": \"w299 bdCell\"})[15].getText().strip()\n",
    "        #     data[\"reform\"] = room_detail_item.findAll(\"td\", {\"class\": \"w299 bdCell\"})[16].getText().strip()\n",
    "        #     data[\"ownership\"] = room_detail_item.findAll(\"td\", {\"class\": \"w299 bdCell\"})[23].getText().strip()\n",
    "        #     data[\"use_district\"] = room_detail_item.findAll(\"td\", {\"class\": \"w299 bdCell\"})[24].getText().strip()\n",
    "        #     data[\"url\"] = room_url\n",
    "        #     data[\"log_date\"] = excution_date\n",
    "        #     all_data.append(data)\n",
    "        # except:\n",
    "        #     error_page.append(room_url)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(work_dir+f'/scraping_raw/kenbiya_baibai_{excution_date}.csv',index = False)\n",
    "    \n",
    "text = 'df_shape:{}\\n'.format(df.shape)\n",
    "write_log(log_file,text)\n",
    "\n",
    "end_time = dt.datetime.now() + dt.timedelta(hours=diff_jst_from_utc)\n",
    "text = 'predicting done.\\nend_time:{}\\n'.format(end_time)\n",
    "write_log(log_file,text)\n",
    "\n",
    "processing_time = end_time - start_time\n",
    "text = 'processing_time:{}\\n'.format(processing_time)\n",
    "write_log(log_file,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9d131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
